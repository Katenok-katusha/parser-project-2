import requests
# используется для отправки запроса на сервер и получения данных с сайта с книгами
from bs4 import BeautifulSoup
# beautifulsoup - это часть библиотеки bs4, является связующей между кодом и веб-сайтом о книгах
def get_page_content(X):   
# извлекает содержимое веб-страницы по URL и выводит ее содержимое, если выборка прошла успешно
  response = requests.get(X) 
# эта строка отправляет запрос на веб-сервер по указанному URL, извлекает содержимое веб-страницы и сохраняет его в переменной response
  if response.status_code == 200:  # 200 - запрос успешен, так как  при таком условии запрошенный контент доступен
      return response.content # возвращает содержимое response, а затем этот контент будет использоваться для дальнейшей обработки, например для извлечения информации о книгах с помощью BeautifulSoup.

def parse_classics_page(X): # эта функция предназначена для извлечения названий книг и цен с определенной веб-страницы
    response = requests.get(X) # requests.get: эта функция предназначена для получения данных с веб-сервера с использованием метода HTTP GET (запрашивает содержимое указанного ресурса). По сути, эта строка кода отправляет запрос на веб-сервер по указанному URL, загружает содержимое  и сохраняет его в переменной ответа для дальнейшей обработки
    response.raise_for_status()  # этот метод проверяет, был ли запрос к веб-сайту успешным, важно проверять наличие ошибок, поскольку без этого программа может продолжить работу, даже если запрос не выполнен, что может привести к неожиданным результатам или даже сбоям. Вызвав исключение, программа может предупредить о проблеме, позволяя изучить и исправить ее.
    soup = BeautifulSoup(response.content, 'html.parser') # этот фрагмент кода берет HTML-содержимое веб-страницы и извлекает из него определенную информацию. BeautifulSoup: это библиотека Python, специально разработанная для работы с данными HTML. «html.parser»: указывает используемый синтаксический анализатор. «html.parser» — это встроенный парсер, входящий в состав библиотеки BeautifulSoup.
    titles = []
    prices = []
# эти строки создают два пустых списка с названиями и ценами. Они будут использоваться для хранения извлеченных данных из HTML.
    for book in soup.find_all('article', class_='product_pod'):
        title = book.find('h3').find('a')['title']
        price = book.find('p', class_='price_color').text.strip()
        titles.append(title)
        prices.append(price)
    return titles, prices
# 19 строка перебирает все элементы с тегом article и классом product_pod внутри объекта soup. find_all() — это метод BeautifulSoup, который находит все подходящие элементы
# 20 строка находит название книги внутри каждого элемента книги.
# book.find('h3') находит тег h3 (представляющий название книги) внутри элемента книги. book.find('h3'). find('a') затем находит тег a (ссылку) внутри тега h3. ['title'] извлекает значение атрибута title из найденного тега.
# 21 строка находит цену книги в каждом элементе книги. book.find('p', class_='price_color') находит тег p (представляющий цену) с классом Price_color внутри элемента книги. .text извлекает текстовое содержимое найденного тега p., .strip() удаляет все начальные и конечные пробелы из извлеченного текста, обеспечивая чистое значение цены
# 23 строка добавляет извлеченную цену в список цен